# CI/CD Enhancements Specification

**Document Type**: Implementation Specification
**Author**: Isaac Morgan - CI/CD Integration Specialist
**Date**: 2025-11-10
**Status**: Ready for Implementation
**Assigned To**: Eric Johnson (FastAPI/Python Specialist)
**Estimated Effort**: 7 hours

---

## Overview

### Purpose

This document specifies three critical enhancements to the CodeRabbit MCP integration that are **BLOCKING** for production CI/CD deployment:

1. **Secret Sanitization** - Security vulnerability without this
2. **Incremental Review** - 60-80% performance improvement
3. **Rate Limit Handling** - Prevents pipeline failures

These enhancements transform the CodeRabbit MCP from a proof-of-concept into a production-grade CI/CD integration.

### Importance

**Without these enhancements:**
- Secrets may leak in pipeline logs (security risk)
- Full codebase reviews cause 3-5 minute pipeline delays
- API rate limits cause pipeline failures
- Integration is unsuitable for production use

**With these enhancements:**
- Secure secret handling
- Fast incremental reviews (30-60 seconds)
- Graceful degradation on API limits
- Production-ready CI/CD integration

### Architecture Context

```
GitHub Actions Pipeline
    ↓
[Git Diff Detection] ← Enhancement 2
    ↓
CodeRabbit MCP Wrapper
    ↓
[Secret Sanitization] ← Enhancement 1
    ↓
[Rate Limit Handling] ← Enhancement 3
    ↓
CodeRabbit API
```

---

## Enhancement 1: Secret Sanitization

**Priority**: CRITICAL (Security)
**Effort**: 2 hours
**Complexity**: Medium

### Requirement

**What it must do:**

Prevent API keys, tokens, passwords, and sensitive data from appearing in:
- Pipeline logs
- MCP server logs
- Tool call responses
- Error messages
- Debug output

**Security Risk Without This:**
```
# BAD - Secret exposed in logs
2025-11-10 10:30:15 INFO: Calling CodeRabbit API with key: coderabbit_sk_abc123xyz789...
2025-11-10 10:30:16 ERROR: API call failed: Invalid key coderabbit_sk_abc123xyz789
```

**Secure Output:**
```
# GOOD - Secret redacted
2025-11-10 10:30:15 INFO: Calling CodeRabbit API with key: [REDACTED]
2025-11-10 10:30:16 ERROR: API call failed: Invalid key [REDACTED]
```

### Implementation Approach

**Step 1: Create Secret Sanitizer Module**

Create `/srv/cc/coderabbit-mcp/src/utils/secret_sanitizer.py`:

```python
import re
from typing import Any, Dict, List, Pattern

class SecretSanitizer:
    """Sanitize secrets from logs and outputs."""

    # Pattern definitions for common secrets
    SECRET_PATTERNS: List[Dict[str, Any]] = [
        {
            'name': 'coderabbit_api_key',
            'pattern': re.compile(r'coderabbit_sk_[a-zA-Z0-9]{32,}'),
            'replacement': '[CODERABBIT_API_KEY_REDACTED]'
        },
        {
            'name': 'github_token',
            'pattern': re.compile(r'gh[ps]_[a-zA-Z0-9]{36,}'),
            'replacement': '[GITHUB_TOKEN_REDACTED]'
        },
        {
            'name': 'bearer_token',
            'pattern': re.compile(r'Bearer\s+[a-zA-Z0-9\-._~+/]+=*', re.IGNORECASE),
            'replacement': 'Bearer [REDACTED]'
        },
        {
            'name': 'password',
            'pattern': re.compile(r'(password|passwd|pwd)[\s:=]+[^\s]{8,}', re.IGNORECASE),
            'replacement': r'\1: [REDACTED]'
        },
        {
            'name': 'api_key',
            'pattern': re.compile(r'(api[_-]?key)[\s:=]+[^\s]{16,}', re.IGNORECASE),
            'replacement': r'\1: [REDACTED]'
        },
        {
            'name': 'authorization_header',
            'pattern': re.compile(r'Authorization:\s*[^\s]+', re.IGNORECASE),
            'replacement': 'Authorization: [REDACTED]'
        }
    ]

    @classmethod
    def sanitize_string(cls, text: str) -> str:
        """Sanitize a single string."""
        if not text:
            return text

        sanitized = text
        for pattern_def in cls.SECRET_PATTERNS:
            sanitized = pattern_def['pattern'].sub(
                pattern_def['replacement'],
                sanitized
            )
        return sanitized

    @classmethod
    def sanitize_dict(cls, data: Dict[str, Any]) -> Dict[str, Any]:
        """Recursively sanitize dictionary values."""
        sanitized = {}
        for key, value in data.items():
            if isinstance(value, str):
                sanitized[key] = cls.sanitize_string(value)
            elif isinstance(value, dict):
                sanitized[key] = cls.sanitize_dict(value)
            elif isinstance(value, list):
                sanitized[key] = cls.sanitize_list(value)
            else:
                sanitized[key] = value
        return sanitized

    @classmethod
    def sanitize_list(cls, data: List[Any]) -> List[Any]:
        """Recursively sanitize list items."""
        sanitized = []
        for item in data:
            if isinstance(item, str):
                sanitized.append(cls.sanitize_string(item))
            elif isinstance(item, dict):
                sanitized.append(cls.sanitize_dict(item))
            elif isinstance(item, list):
                sanitized.append(cls.sanitize_list(item))
            else:
                sanitized.append(item)
        return sanitized

    @classmethod
    def sanitize_any(cls, data: Any) -> Any:
        """Sanitize any data type."""
        if isinstance(data, str):
            return cls.sanitize_string(data)
        elif isinstance(data, dict):
            return cls.sanitize_dict(data)
        elif isinstance(data, list):
            return cls.sanitize_list(data)
        else:
            return data
```

**Step 2: Create Sanitizing Logger**

Create `/srv/cc/coderabbit-mcp/src/utils/sanitizing_logger.py`:

```python
import logging
from typing import Any
from .secret_sanitizer import SecretSanitizer

class SanitizingFormatter(logging.Formatter):
    """Logging formatter that sanitizes secrets."""

    def format(self, record: logging.LogRecord) -> str:
        # Sanitize the message
        if isinstance(record.msg, str):
            record.msg = SecretSanitizer.sanitize_string(record.msg)

        # Sanitize arguments
        if record.args:
            if isinstance(record.args, dict):
                record.args = SecretSanitizer.sanitize_dict(record.args)
            elif isinstance(record.args, tuple):
                record.args = tuple(SecretSanitizer.sanitize_any(arg) for arg in record.args)

        # Sanitize exception info
        if record.exc_text:
            record.exc_text = SecretSanitizer.sanitize_string(record.exc_text)

        return super().format(record)

def get_sanitizing_logger(name: str) -> logging.Logger:
    """Get a logger with secret sanitization."""
    logger = logging.getLogger(name)

    # Remove existing handlers
    logger.handlers.clear()

    # Add sanitizing handler
    handler = logging.StreamHandler()
    formatter = SanitizingFormatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    return logger
```

**Step 3: Integrate into MCP Server**

Update `/srv/cc/coderabbit-mcp/src/coderabbit_mcp/server.py`:

```python
from utils.sanitizing_logger import get_sanitizing_logger
from utils.secret_sanitizer import SecretSanitizer

# Replace standard logger
logger = get_sanitizing_logger(__name__)

# Sanitize tool responses
@server.call_tool()
async def call_tool(name: str, arguments: Any) -> List[TextContent]:
    try:
        result = await execute_tool(name, arguments)

        # Sanitize result before returning
        sanitized_result = SecretSanitizer.sanitize_any(result)

        return [TextContent(type="text", text=json.dumps(sanitized_result, indent=2))]
    except Exception as e:
        # Sanitize error message
        error_msg = SecretSanitizer.sanitize_string(str(e))
        logger.error(f"Tool execution failed: {error_msg}")
        raise
```

**Step 4: Add Environment Variable Protection**

Update `/srv/cc/coderabbit-mcp/src/coderabbit_mcp/config.py`:

```python
from utils.secret_sanitizer import SecretSanitizer

class Config:
    def __init__(self):
        self.api_key = os.getenv("CODERABBIT_API_KEY")
        self.github_token = os.getenv("GITHUB_TOKEN")

    def __repr__(self) -> str:
        """Safe representation with sanitized secrets."""
        return f"Config(api_key=[REDACTED], github_token=[REDACTED])"

    def to_dict_safe(self) -> Dict[str, str]:
        """Dictionary with sanitized values for logging."""
        return {
            "api_key": "[REDACTED]",
            "github_token": "[REDACTED]",
            "other_config": self.other_config
        }
```

### Code Examples

**Example 1: Sanitize API Call Logs**

```python
# Before sanitization
logger.info(f"Calling CodeRabbit API: {api_url}")
logger.debug(f"Headers: {headers}")  # Contains Authorization: Bearer token
logger.debug(f"API Key: {config.api_key}")

# After sanitization (automatic)
logger.info(f"Calling CodeRabbit API: {api_url}")
logger.debug(f"Headers: {headers}")  # Authorization: [REDACTED]
logger.debug(f"API Key: {config.api_key}")  # [CODERABBIT_API_KEY_REDACTED]
```

**Example 2: Sanitize Error Messages**

```python
try:
    response = await client.post(url, headers={"Authorization": f"Bearer {token}"})
except Exception as e:
    # Error message automatically sanitized
    logger.error(f"API call failed: {e}")
    # Output: "API call failed: 401 Unauthorized for token [REDACTED]"
```

**Example 3: Sanitize Tool Responses**

```python
@server.call_tool()
async def call_tool(name: str, arguments: Any) -> List[TextContent]:
    result = {
        "status": "success",
        "api_key": config.api_key,  # Will be sanitized
        "data": response_data
    }

    # Sanitize before returning
    sanitized = SecretSanitizer.sanitize_dict(result)
    return [TextContent(type="text", text=json.dumps(sanitized))]
```

### Testing

**Test 1: Unit Tests for Secret Patterns**

Create `/srv/cc/coderabbit-mcp/tests/test_secret_sanitizer.py`:

```python
import pytest
from src.utils.secret_sanitizer import SecretSanitizer

def test_coderabbit_api_key_sanitization():
    text = "Using API key: coderabbit_sk_abc123xyz789def456"
    result = SecretSanitizer.sanitize_string(text)
    assert "coderabbit_sk_" not in result
    assert "[CODERABBIT_API_KEY_REDACTED]" in result

def test_github_token_sanitization():
    text = "GitHub token: ghp_abc123xyz789def456uvw789"
    result = SecretSanitizer.sanitize_string(text)
    assert "ghp_" not in result
    assert "[GITHUB_TOKEN_REDACTED]" in result

def test_bearer_token_sanitization():
    text = "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9"
    result = SecretSanitizer.sanitize_string(text)
    assert "eyJhbGci" not in result
    assert "Bearer [REDACTED]" in result

def test_password_sanitization():
    text = "password: MySecureP@ssw0rd123"
    result = SecretSanitizer.sanitize_string(text)
    assert "MySecureP@ssw0rd123" not in result
    assert "password: [REDACTED]" in result

def test_dict_sanitization():
    data = {
        "api_key": "coderabbit_sk_secret123",
        "username": "testuser",
        "nested": {
            "token": "ghp_token456"
        }
    }
    result = SecretSanitizer.sanitize_dict(data)
    assert "coderabbit_sk_" not in str(result)
    assert "ghp_token456" not in str(result)
    assert result["username"] == "testuser"

def test_list_sanitization():
    data = [
        "api_key: coderabbit_sk_abc123",
        {"token": "ghp_xyz789"},
        "normal text"
    ]
    result = SecretSanitizer.sanitize_list(data)
    assert "coderabbit_sk_" not in str(result)
    assert "ghp_xyz789" not in str(result)
    assert "normal text" in result
```

**Test 2: Logger Integration Test**

```python
import logging
from io import StringIO
from src.utils.sanitizing_logger import get_sanitizing_logger

def test_sanitizing_logger():
    # Capture log output
    log_stream = StringIO()
    handler = logging.StreamHandler(log_stream)

    logger = get_sanitizing_logger("test")
    logger.handlers = [handler]

    # Log message with secret
    logger.info("API call with key: coderabbit_sk_secret123")

    # Check output
    output = log_stream.getvalue()
    assert "coderabbit_sk_secret123" not in output
    assert "[CODERABBIT_API_KEY_REDACTED]" in output
```

**Test 3: Manual Pipeline Test**

```bash
# Set environment variable with test secret
export CODERABBIT_API_KEY="coderabbit_sk_test_secret_key_12345"

# Run MCP server and trigger review
python -m coderabbit_mcp.server

# Check logs - secret should NOT appear
tail -f /var/log/coderabbit-mcp/server.log | grep -i "coderabbit_sk_"
# Should return NO results

# Verify sanitization marker appears
tail -f /var/log/coderabbit-mcp/server.log | grep "REDACTED"
# Should show sanitized entries
```

### Success Criteria

- [ ] All secret patterns detected and sanitized
- [ ] No secrets appear in any log output
- [ ] No secrets in MCP tool responses
- [ ] No secrets in error messages
- [ ] Unit tests pass with 100% coverage
- [ ] Manual pipeline test shows no secret leakage
- [ ] Performance impact < 5ms per log entry
- [ ] Works with all logging levels (DEBUG, INFO, ERROR)

---

## Enhancement 2: Incremental Review

**Priority**: CRITICAL (Performance)
**Effort**: 3 hours
**Complexity**: High

### Requirement

**What it must do:**

Review ONLY the files changed in a pull request, not the entire codebase.

**Performance Impact:**
- Full codebase review: 3-5 minutes (100+ files)
- Incremental review: 30-60 seconds (5-10 files)
- **Improvement: 60-80% faster**

**Current Behavior (Inefficient):**
```bash
# Reviews ALL 250 files in repository
coderabbit_review_code --repo owner/repo --pr 123
# Takes 4 minutes, wastes API quota
```

**Desired Behavior (Efficient):**
```bash
# Reviews ONLY 8 changed files
coderabbit_review_code --repo owner/repo --pr 123 --incremental
# Takes 45 seconds, conserves API quota
```

### Implementation Approach

**Step 1: Git Diff Detection**

Create `/srv/cc/coderabbit-mcp/src/utils/git_diff_detector.py`:

```python
import subprocess
from typing import List, Set, Optional
from dataclasses import dataclass
from pathlib import Path

@dataclass
class ChangedFile:
    """Represents a file changed in a PR."""
    path: str
    status: str  # 'added', 'modified', 'deleted', 'renamed'
    additions: int
    deletions: int
    old_path: Optional[str] = None  # For renamed files

class GitDiffDetector:
    """Detect changed files in a pull request."""

    @staticmethod
    def get_changed_files_pr(
        repo_path: str,
        base_branch: str,
        head_branch: str
    ) -> List[ChangedFile]:
        """Get files changed between base and head branches."""
        try:
            # Get list of changed files with stats
            cmd = [
                "git", "-C", repo_path,
                "diff", "--name-status", "--numstat",
                f"{base_branch}...{head_branch}"
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )

            return GitDiffDetector._parse_diff_output(result.stdout)

        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Git diff failed: {e.stderr}")

    @staticmethod
    def get_changed_files_commit(
        repo_path: str,
        commit_sha: str
    ) -> List[ChangedFile]:
        """Get files changed in a specific commit."""
        try:
            cmd = [
                "git", "-C", repo_path,
                "diff", "--name-status", "--numstat",
                f"{commit_sha}^", commit_sha
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )

            return GitDiffDetector._parse_diff_output(result.stdout)

        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Git diff failed: {e.stderr}")

    @staticmethod
    def _parse_diff_output(output: str) -> List[ChangedFile]:
        """Parse git diff output into ChangedFile objects."""
        changed_files = []

        for line in output.strip().split('\n'):
            if not line:
                continue

            parts = line.split('\t')
            if len(parts) < 2:
                continue

            # Parse numstat format: additions deletions filename
            if parts[0].isdigit():
                additions = int(parts[0])
                deletions = int(parts[1])
                path = parts[2]
                status = 'modified'
            else:
                # Parse name-status format: status filename
                status_code = parts[0][0]
                path = parts[1]
                additions = 0
                deletions = 0

                status_map = {
                    'A': 'added',
                    'M': 'modified',
                    'D': 'deleted',
                    'R': 'renamed'
                }
                status = status_map.get(status_code, 'modified')

                # Handle renamed files
                old_path = parts[2] if status == 'renamed' and len(parts) > 2 else None

            changed_files.append(ChangedFile(
                path=path,
                status=status,
                additions=additions,
                deletions=deletions,
                old_path=old_path
            ))

        return changed_files

    @staticmethod
    def filter_reviewable_files(
        changed_files: List[ChangedFile],
        include_patterns: Optional[List[str]] = None,
        exclude_patterns: Optional[List[str]] = None
    ) -> List[ChangedFile]:
        """Filter files to only those that should be reviewed."""

        # Default exclusions
        default_excludes = [
            "*.lock",           # Lock files
            "*.min.js",         # Minified files
            "*.map",            # Source maps
            "package-lock.json",
            "pnpm-lock.yaml",
            "yarn.lock",
            "node_modules/*",
            "dist/*",
            "build/*",
            ".git/*"
        ]

        exclude_patterns = exclude_patterns or default_excludes

        reviewable = []
        for file in changed_files:
            # Skip deleted files
            if file.status == 'deleted':
                continue

            # Check exclusions
            if any(Path(file.path).match(pattern) for pattern in exclude_patterns):
                continue

            # Check inclusions (if specified)
            if include_patterns:
                if not any(Path(file.path).match(pattern) for pattern in include_patterns):
                    continue

            reviewable.append(file)

        return reviewable
```

**Step 2: Update MCP Tool for Incremental Review**

Update `/srv/cc/coderabbit-mcp/src/coderabbit_mcp/tools.py`:

```python
from utils.git_diff_detector import GitDiffDetector, ChangedFile
from typing import List, Optional

async def review_code_incremental(
    repo_owner: str,
    repo_name: str,
    pr_number: int,
    base_branch: str = "main",
    include_patterns: Optional[List[str]] = None,
    exclude_patterns: Optional[List[str]] = None
) -> Dict[str, Any]:
    """Review only files changed in the pull request."""

    # Step 1: Clone or fetch repository
    repo_path = f"/tmp/repos/{repo_owner}/{repo_name}"
    await ensure_repo_cloned(repo_owner, repo_name, repo_path)

    # Step 2: Fetch PR information
    pr_info = await github_client.get_pull_request(repo_owner, repo_name, pr_number)
    head_branch = pr_info["head"]["ref"]
    base_branch = pr_info["base"]["ref"]

    # Step 3: Detect changed files
    changed_files = GitDiffDetector.get_changed_files_pr(
        repo_path=repo_path,
        base_branch=base_branch,
        head_branch=head_branch
    )

    logger.info(f"Detected {len(changed_files)} changed files")

    # Step 4: Filter to reviewable files
    reviewable_files = GitDiffDetector.filter_reviewable_files(
        changed_files,
        include_patterns=include_patterns,
        exclude_patterns=exclude_patterns
    )

    logger.info(f"Reviewing {len(reviewable_files)} files (after filtering)")

    # Step 5: Review only changed files
    reviews = []
    for file in reviewable_files:
        file_path = Path(repo_path) / file.path

        if not file_path.exists():
            logger.warning(f"File not found: {file.path}")
            continue

        file_content = file_path.read_text()

        review = await coderabbit_client.review_file(
            filename=file.path,
            content=file_content,
            context={
                "repo": f"{repo_owner}/{repo_name}",
                "pr": pr_number,
                "status": file.status,
                "additions": file.additions,
                "deletions": file.deletions
            }
        )

        reviews.append({
            "file": file.path,
            "status": file.status,
            "review": review
        })

    return {
        "pr_number": pr_number,
        "files_changed": len(changed_files),
        "files_reviewed": len(reviews),
        "reviews": reviews,
        "incremental": True
    }
```

**Step 3: Add GitHub Actions Integration**

Create `/srv/cc/coderabbit-mcp/examples/github-actions-incremental.yml`:

```yaml
name: CodeRabbit Incremental Review

on:
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  coderabbit-review:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for accurate diffs

      - name: Get changed files
        id: changed-files
        run: |
          # Get list of changed files
          CHANGED_FILES=$(git diff --name-only origin/${{ github.base_ref }}...HEAD)
          echo "files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          # Count files
          FILE_COUNT=$(echo "$CHANGED_FILES" | wc -l)
          echo "count=$FILE_COUNT" >> $GITHUB_OUTPUT

      - name: CodeRabbit Incremental Review
        uses: coderabbitai/github-action@v1
        with:
          mode: 'incremental'
          files: ${{ steps.changed-files.outputs.files }}
          include_patterns: |
            *.py
            *.js
            *.ts
            *.tsx
          exclude_patterns: |
            *.lock
            *.min.js
            dist/*
        env:
          CODERABBIT_API_KEY: ${{ secrets.CODERABBIT_API_KEY }}

      - name: Performance Summary
        run: |
          echo "Files changed: ${{ steps.changed-files.outputs.count }}"
          echo "Review mode: Incremental (fast)"
          echo "Estimated time: 30-60 seconds"
```

### Code Examples

**Example 1: Detect Changed Files**

```python
# In CI/CD pipeline
detector = GitDiffDetector()

# Get files changed in PR
changed_files = detector.get_changed_files_pr(
    repo_path="/workspace/myproject",
    base_branch="origin/main",
    head_branch="origin/feature-branch"
)

print(f"Changed files: {len(changed_files)}")
for file in changed_files:
    print(f"  {file.status}: {file.path} (+{file.additions}/-{file.deletions})")

# Output:
# Changed files: 8
#   modified: src/api/users.py (+45/-12)
#   added: src/api/auth.py (+120/-0)
#   modified: tests/test_users.py (+30/-5)
```

**Example 2: Filter Reviewable Files**

```python
# Filter to reviewable files
reviewable = detector.filter_reviewable_files(
    changed_files,
    include_patterns=["*.py", "*.js"],
    exclude_patterns=["*.lock", "dist/*"]
)

print(f"Reviewable files: {len(reviewable)}")
# Output: Reviewable files: 5 (excludes lock files, dist/)
```

**Example 3: Incremental Review MCP Call**

```python
# MCP tool call
result = await mcp_client.call_tool(
    "coderabbit_review_code_incremental",
    {
        "repo_owner": "my-org",
        "repo_name": "my-project",
        "pr_number": 123,
        "include_patterns": ["*.py", "*.ts"],
        "exclude_patterns": ["*.lock", "dist/*"]
    }
)

# Result:
# {
#   "pr_number": 123,
#   "files_changed": 15,
#   "files_reviewed": 8,
#   "reviews": [...],
#   "incremental": true
# }
```

### Testing

**Test 1: Git Diff Detection Accuracy**

```python
import pytest
from src.utils.git_diff_detector import GitDiffDetector

def test_detect_changed_files_pr(setup_git_repo):
    """Test detecting changed files in a PR."""
    repo_path = setup_git_repo

    # Create test branches and commits
    # ... setup code ...

    changed_files = GitDiffDetector.get_changed_files_pr(
        repo_path=repo_path,
        base_branch="main",
        head_branch="feature"
    )

    assert len(changed_files) == 3
    assert changed_files[0].path == "src/new_feature.py"
    assert changed_files[0].status == "added"

def test_filter_reviewable_files():
    """Test filtering to reviewable files."""
    files = [
        ChangedFile("src/api.py", "modified", 10, 5),
        ChangedFile("package-lock.json", "modified", 500, 200),
        ChangedFile("dist/bundle.js", "added", 1000, 0)
    ]

    reviewable = GitDiffDetector.filter_reviewable_files(files)

    assert len(reviewable) == 1
    assert reviewable[0].path == "src/api.py"
```

**Test 2: Performance Comparison**

```bash
#!/bin/bash
# Compare full vs incremental review performance

echo "Full codebase review (baseline):"
time coderabbit_review_code --repo my-org/my-project --pr 123

echo ""
echo "Incremental review (optimized):"
time coderabbit_review_code --repo my-org/my-project --pr 123 --incremental

# Expected output:
# Full codebase review: 4m 32s
# Incremental review: 0m 47s
# Improvement: 82% faster
```

**Test 3: GitHub Actions Integration Test**

```yaml
# .github/workflows/test-incremental.yml
name: Test Incremental Review

on:
  pull_request:

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Test Changed Files Detection
        run: |
          CHANGED=$(git diff --name-only origin/${{ github.base_ref }}...HEAD | wc -l)
          echo "Changed files: $CHANGED"

          if [ $CHANGED -eq 0 ]; then
            echo "ERROR: No changed files detected"
            exit 1
          fi

          echo "SUCCESS: Detected $CHANGED changed files"
```

### Success Criteria

- [ ] Accurately detects all changed files in PR
- [ ] Correctly identifies file status (added/modified/deleted/renamed)
- [ ] Filters out non-reviewable files (lock files, dist/)
- [ ] Honors include/exclude patterns
- [ ] 60-80% performance improvement vs full review
- [ ] Review time: 30-60 seconds for typical PRs (5-10 files)
- [ ] GitHub Actions integration works correctly
- [ ] Unit tests pass with 95%+ coverage
- [ ] Works with renamed files
- [ ] Handles edge cases (empty PRs, binary files, large files)

---

## Enhancement 3: Rate Limit Handling

**Priority**: HIGH (Reliability)
**Effort**: 2 hours
**Complexity**: Medium

### Requirement

**What it must do:**

Gracefully handle CodeRabbit API rate limits to prevent pipeline failures.

**Current Behavior (Pipeline Fails):**
```
ERROR: CodeRabbit API rate limit exceeded (429 Too Many Requests)
Pipeline FAILED - Exit code 1
Build blocked, deployment halted
```

**Desired Behavior (Graceful Degradation):**
```
WARNING: CodeRabbit API rate limit reached
Retrying in 60 seconds (attempt 1/3)...
WARNING: Rate limit persists, reducing review scope
Pipeline CONTINUES with partial review
Exit code 0 (success with warnings)
```

**Rate Limit Scenarios:**

1. **Temporary spike**: Retry with exponential backoff
2. **Sustained limit**: Reduce review scope (critical files only)
3. **Hard limit**: Skip review, warn user, continue pipeline

### Implementation Approach

**Step 1: Rate Limit Detector**

Create `/srv/cc/coderabbit-mcp/src/utils/rate_limit_handler.py`:

```python
import time
import asyncio
from typing import Optional, Callable, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

@dataclass
class RateLimitInfo:
    """Rate limit information from API response."""
    limit: int
    remaining: int
    reset_at: datetime
    retry_after: Optional[int] = None  # Seconds until retry

class RateLimitHandler:
    """Handle API rate limits with retry and backoff."""

    def __init__(
        self,
        max_retries: int = 3,
        base_delay: int = 60,
        max_delay: int = 300,
        backoff_factor: float = 2.0
    ):
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.max_delay = max_delay
        self.backoff_factor = backoff_factor

        self.current_limit_info: Optional[RateLimitInfo] = None

    async def execute_with_retry(
        self,
        func: Callable,
        *args,
        **kwargs
    ) -> Any:
        """Execute function with automatic retry on rate limit."""

        for attempt in range(self.max_retries + 1):
            try:
                result = await func(*args, **kwargs)

                # Extract rate limit info from response headers
                if hasattr(result, 'headers'):
                    self._update_rate_limit_info(result.headers)

                return result

            except RateLimitError as e:
                if attempt == self.max_retries:
                    logger.error(f"Rate limit exceeded after {self.max_retries} retries")
                    raise RateLimitExhausted(
                        f"CodeRabbit API rate limit exceeded. "
                        f"Reset at: {e.reset_at}"
                    )

                delay = self._calculate_backoff(attempt, e.retry_after)
                logger.warning(
                    f"Rate limit hit (attempt {attempt + 1}/{self.max_retries}). "
                    f"Retrying in {delay}s..."
                )

                await asyncio.sleep(delay)

            except Exception as e:
                # Non-rate-limit error, don't retry
                raise

    def _calculate_backoff(
        self,
        attempt: int,
        retry_after: Optional[int] = None
    ) -> int:
        """Calculate exponential backoff delay."""

        # Use API's retry-after if provided
        if retry_after:
            return min(retry_after, self.max_delay)

        # Exponential backoff: base * (factor ^ attempt)
        delay = self.base_delay * (self.backoff_factor ** attempt)
        return min(int(delay), self.max_delay)

    def _update_rate_limit_info(self, headers: dict):
        """Extract and store rate limit info from headers."""
        try:
            self.current_limit_info = RateLimitInfo(
                limit=int(headers.get('X-RateLimit-Limit', 0)),
                remaining=int(headers.get('X-RateLimit-Remaining', 0)),
                reset_at=datetime.fromtimestamp(
                    int(headers.get('X-RateLimit-Reset', 0))
                ),
                retry_after=int(headers.get('Retry-After', 0)) or None
            )

            # Log if approaching limit
            if self.current_limit_info.remaining < 10:
                logger.warning(
                    f"Approaching rate limit: {self.current_limit_info.remaining} "
                    f"requests remaining"
                )

        except (ValueError, KeyError) as e:
            logger.debug(f"Could not parse rate limit headers: {e}")

    def get_wait_time(self) -> Optional[int]:
        """Get seconds to wait before next request."""
        if not self.current_limit_info:
            return None

        if self.current_limit_info.remaining > 0:
            return 0

        now = datetime.now()
        if now < self.current_limit_info.reset_at:
            return int((self.current_limit_info.reset_at - now).total_seconds())

        return 0

class RateLimitError(Exception):
    """API rate limit exceeded."""
    def __init__(self, message: str, reset_at: datetime, retry_after: Optional[int] = None):
        super().__init__(message)
        self.reset_at = reset_at
        self.retry_after = retry_after

class RateLimitExhausted(Exception):
    """Rate limit exceeded and retries exhausted."""
    pass
```

**Step 2: Graceful Degradation Strategy**

Create `/srv/cc/coderabbit-mcp/src/utils/review_fallback.py`:

```python
from typing import List, Dict, Any
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)

@dataclass
class ReviewScope:
    """Defines scope of code review."""
    mode: str  # 'full', 'critical', 'minimal', 'skip'
    files: List[str]
    rationale: str

class ReviewFallbackStrategy:
    """Implement graceful degradation for rate-limited reviews."""

    CRITICAL_FILE_PATTERNS = [
        "src/api/*.py",
        "src/auth/*.py",
        "src/security/*.py",
        "src/database/*.py",
        "*.sql",
        "Dockerfile",
        "docker-compose.yml"
    ]

    @staticmethod
    def determine_scope(
        changed_files: List[str],
        rate_limit_hit: bool,
        retries_exhausted: bool
    ) -> ReviewScope:
        """Determine appropriate review scope based on rate limit status."""

        if not rate_limit_hit:
            return ReviewScope(
                mode='full',
                files=changed_files,
                rationale="No rate limits, performing full review"
            )

        if not retries_exhausted:
            # Retry in progress, maintain full scope
            return ReviewScope(
                mode='full',
                files=changed_files,
                rationale="Retrying full review after rate limit"
            )

        # Retries exhausted, degrade gracefully
        critical_files = ReviewFallbackStrategy._filter_critical_files(changed_files)

        if critical_files:
            logger.warning(
                f"Rate limit exhausted. Reviewing {len(critical_files)} critical files only."
            )
            return ReviewScope(
                mode='critical',
                files=critical_files,
                rationale=f"Rate limit exceeded. Reviewing critical files only: "
                         f"{', '.join(critical_files)}"
            )

        # No critical files, skip review but continue pipeline
        logger.warning("Rate limit exhausted. Skipping review, continuing pipeline.")
        return ReviewScope(
            mode='skip',
            files=[],
            rationale="Rate limit exceeded. No critical files changed. "
                     "Skipping review to avoid blocking pipeline."
        )

    @staticmethod
    def _filter_critical_files(files: List[str]) -> List[str]:
        """Filter list to only critical files."""
        from pathlib import Path

        critical = []
        for file in files:
            for pattern in ReviewFallbackStrategy.CRITICAL_FILE_PATTERNS:
                if Path(file).match(pattern):
                    critical.append(file)
                    break

        return critical
```

**Step 3: Integrate into MCP Tool**

Update `/srv/cc/coderabbit-mcp/src/coderabbit_mcp/tools.py`:

```python
from utils.rate_limit_handler import RateLimitHandler, RateLimitError, RateLimitExhausted
from utils.review_fallback import ReviewFallbackStrategy, ReviewScope

rate_limit_handler = RateLimitHandler(
    max_retries=3,
    base_delay=60,
    max_delay=300
)

async def review_code_with_rate_limiting(
    repo_owner: str,
    repo_name: str,
    pr_number: int
) -> Dict[str, Any]:
    """Review code with automatic rate limit handling."""

    # Get changed files
    changed_files = await get_changed_files(repo_owner, repo_name, pr_number)

    try:
        # Attempt review with retry
        result = await rate_limit_handler.execute_with_retry(
            _perform_review,
            repo_owner, repo_name, pr_number, changed_files
        )

        return {
            "status": "success",
            "scope": "full",
            "result": result
        }

    except RateLimitExhausted as e:
        # Determine fallback scope
        scope = ReviewFallbackStrategy.determine_scope(
            changed_files=changed_files,
            rate_limit_hit=True,
            retries_exhausted=True
        )

        if scope.mode == 'skip':
            logger.warning(scope.rationale)
            return {
                "status": "skipped",
                "scope": "none",
                "rationale": scope.rationale,
                "rate_limit_info": str(e)
            }

        # Perform critical-only review
        result = await _perform_review(
            repo_owner, repo_name, pr_number, scope.files
        )

        return {
            "status": "partial",
            "scope": scope.mode,
            "files_reviewed": len(scope.files),
            "rationale": scope.rationale,
            "result": result
        }

async def _perform_review(
    repo_owner: str,
    repo_name: str,
    pr_number: int,
    files: List[str]
) -> Dict[str, Any]:
    """Perform the actual code review."""
    response = await coderabbit_client.review_pr(
        repo_owner, repo_name, pr_number, files
    )

    # Check for rate limit in response
    if response.status_code == 429:
        retry_after = int(response.headers.get('Retry-After', 60))
        reset_at = datetime.fromtimestamp(
            int(response.headers.get('X-RateLimit-Reset', time.time() + retry_after))
        )
        raise RateLimitError(
            "Rate limit exceeded",
            reset_at=reset_at,
            retry_after=retry_after
        )

    return response.json()
```

**Step 4: CI/CD Pipeline Integration**

Update GitHub Actions workflow:

```yaml
name: CodeRabbit Review with Rate Limit Handling

on:
  pull_request:

jobs:
  coderabbit:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: CodeRabbit Review
        id: review
        continue-on-error: true  # Don't fail pipeline on rate limit
        uses: coderabbitai/action@v1
        with:
          mode: incremental
          rate_limit_strategy: graceful_degradation
        env:
          CODERABBIT_API_KEY: ${{ secrets.CODERABBIT_API_KEY }}

      - name: Handle Review Result
        run: |
          if [ "${{ steps.review.outputs.status }}" = "skipped" ]; then
            echo "⚠️ CodeRabbit review skipped due to rate limits"
            echo "Rationale: ${{ steps.review.outputs.rationale }}"
            echo "Pipeline continuing..."
            exit 0  # Success with warning
          elif [ "${{ steps.review.outputs.status }}" = "partial" ]; then
            echo "⚠️ Partial CodeRabbit review completed"
            echo "Scope: ${{ steps.review.outputs.scope }}"
            echo "Files reviewed: ${{ steps.review.outputs.files_reviewed }}"
            exit 0  # Success with warning
          else
            echo "✅ Full CodeRabbit review completed"
            exit 0
          fi
```

### Code Examples

**Example 1: Basic Rate Limit Retry**

```python
handler = RateLimitHandler(max_retries=3, base_delay=60)

try:
    result = await handler.execute_with_retry(
        coderabbit_client.review_pr,
        repo_owner="my-org",
        repo_name="my-project",
        pr_number=123
    )
    print("Review completed:", result)
except RateLimitExhausted:
    print("Rate limit exceeded, falling back to critical files only")
```

**Example 2: Graceful Degradation**

```python
# Determine review scope based on rate limit
scope = ReviewFallbackStrategy.determine_scope(
    changed_files=["src/api/users.py", "README.md", "tests/test_api.py"],
    rate_limit_hit=True,
    retries_exhausted=True
)

if scope.mode == 'critical':
    print(f"Reviewing critical files only: {scope.files}")
    # Review only: src/api/users.py
elif scope.mode == 'skip':
    print("Skipping review to avoid blocking pipeline")
```

**Example 3: Rate Limit Monitoring**

```python
handler = RateLimitHandler()

# Make API call
result = await handler.execute_with_retry(api_call)

# Check rate limit status
if handler.current_limit_info:
    print(f"Rate limit: {handler.current_limit_info.remaining}/{handler.current_limit_info.limit}")
    print(f"Resets at: {handler.current_limit_info.reset_at}")

    if handler.current_limit_info.remaining < 10:
        print("WARNING: Approaching rate limit!")
```

### Testing

**Test 1: Rate Limit Retry Logic**

```python
import pytest
from unittest.mock import AsyncMock, patch
from src.utils.rate_limit_handler import RateLimitHandler, RateLimitError

@pytest.mark.asyncio
async def test_retry_on_rate_limit():
    """Test automatic retry on rate limit."""
    handler = RateLimitHandler(max_retries=3, base_delay=1)

    # Mock function that fails twice then succeeds
    mock_func = AsyncMock(
        side_effect=[
            RateLimitError("Rate limit", datetime.now() + timedelta(seconds=60)),
            RateLimitError("Rate limit", datetime.now() + timedelta(seconds=60)),
            {"status": "success"}
        ]
    )

    result = await handler.execute_with_retry(mock_func)

    assert result["status"] == "success"
    assert mock_func.call_count == 3

@pytest.mark.asyncio
async def test_exponential_backoff():
    """Test exponential backoff calculation."""
    handler = RateLimitHandler(base_delay=10, backoff_factor=2.0)

    assert handler._calculate_backoff(0) == 10   # 10 * 2^0
    assert handler._calculate_backoff(1) == 20   # 10 * 2^1
    assert handler._calculate_backoff(2) == 40   # 10 * 2^2
```

**Test 2: Fallback Strategy**

```python
def test_determine_scope_full():
    """Test full review scope when no rate limit."""
    files = ["src/api.py", "README.md"]

    scope = ReviewFallbackStrategy.determine_scope(
        changed_files=files,
        rate_limit_hit=False,
        retries_exhausted=False
    )

    assert scope.mode == 'full'
    assert scope.files == files

def test_determine_scope_critical():
    """Test critical-only scope on rate limit."""
    files = ["src/api/auth.py", "README.md", "docs/guide.md"]

    scope = ReviewFallbackStrategy.determine_scope(
        changed_files=files,
        rate_limit_hit=True,
        retries_exhausted=True
    )

    assert scope.mode == 'critical'
    assert "src/api/auth.py" in scope.files
    assert "README.md" not in scope.files

def test_determine_scope_skip():
    """Test skip mode when no critical files."""
    files = ["README.md", "docs/guide.md"]

    scope = ReviewFallbackStrategy.determine_scope(
        changed_files=files,
        rate_limit_hit=True,
        retries_exhausted=True
    )

    assert scope.mode == 'skip'
    assert len(scope.files) == 0
```

**Test 3: Integration Test**

```bash
#!/bin/bash
# Simulate rate limit scenario

# Set low rate limit for testing
export CODERABBIT_RATE_LIMIT_TEST=1

# Run review that will hit rate limit
python -m coderabbit_mcp.cli review \
  --repo my-org/my-project \
  --pr 123 \
  --rate-limit-strategy graceful

# Check exit code
if [ $? -eq 0 ]; then
  echo "SUCCESS: Pipeline continued despite rate limit"
else
  echo "FAILURE: Pipeline blocked by rate limit"
  exit 1
fi
```

### Success Criteria

- [ ] Automatic retry on rate limit (up to 3 attempts)
- [ ] Exponential backoff implemented correctly
- [ ] Respects API's `Retry-After` header
- [ ] Graceful degradation to critical files only
- [ ] Pipeline never fails due to rate limits
- [ ] Clear warnings logged for rate limit events
- [ ] Rate limit status tracked and reported
- [ ] Unit tests pass with 90%+ coverage
- [ ] Integration test passes in CI/CD
- [ ] Documentation includes rate limit handling

---

## Integration with Existing Code

### Parser Integration

The three enhancements integrate with Carlos's existing parser:

```python
# src/coderabbit_mcp/server.py

from utils.secret_sanitizer import SecretSanitizer
from utils.git_diff_detector import GitDiffDetector
from utils.rate_limit_handler import RateLimitHandler

# Enhancement 1: Sanitize parser output
@server.call_tool()
async def parse_review_output(raw_output: str) -> Dict[str, Any]:
    parsed = await parser.parse(raw_output)

    # Sanitize before returning
    sanitized = SecretSanitizer.sanitize_dict(parsed)
    return sanitized

# Enhancement 2: Incremental parsing
@server.call_tool()
async def review_with_incremental(repo_owner: str, repo_name: str, pr: int):
    # Detect changed files
    changed_files = GitDiffDetector.get_changed_files_pr(...)

    # Review only changed files
    for file in changed_files:
        raw_output = await coderabbit_client.review_file(file)
        parsed = await parser.parse(raw_output)
        # Process parsed review...

# Enhancement 3: Rate limit aware parsing
rate_handler = RateLimitHandler()

@server.call_tool()
async def review_with_rate_limiting(repo_owner: str, repo_name: str, pr: int):
    try:
        result = await rate_handler.execute_with_retry(
            _perform_review_and_parse,
            repo_owner, repo_name, pr
        )
        return result
    except RateLimitExhausted:
        # Fallback to critical files
        # ...
```

### Wrapper Integration

The enhancements work seamlessly with the CLI wrapper:

```python
# src/coderabbit_mcp/cli.py

import click
from utils.secret_sanitizer import SecretSanitizer
from utils.git_diff_detector import GitDiffDetector
from utils.rate_limit_handler import RateLimitHandler

@click.command()
@click.option('--repo', required=True)
@click.option('--pr', type=int, required=True)
@click.option('--incremental/--full', default=True)
@click.option('--rate-limit-strategy', type=click.Choice(['retry', 'graceful', 'fail']))
def review_pr(repo: str, pr: int, incremental: bool, rate_limit_strategy: str):
    """Review pull request with all enhancements."""

    # Enhancement 2: Incremental review
    if incremental:
        changed_files = GitDiffDetector.get_changed_files_pr(...)
        click.echo(f"Reviewing {len(changed_files)} changed files")
    else:
        changed_files = get_all_files()
        click.echo(f"Full review: {len(changed_files)} files")

    # Enhancement 3: Rate limit handling
    rate_handler = RateLimitHandler()

    try:
        result = await rate_handler.execute_with_retry(
            perform_review,
            changed_files
        )

        # Enhancement 1: Sanitize output
        sanitized_result = SecretSanitizer.sanitize_dict(result)

        click.echo(json.dumps(sanitized_result, indent=2))

    except RateLimitExhausted:
        if rate_limit_strategy == 'graceful':
            click.echo("Rate limit exceeded, using fallback strategy")
            # Fallback logic...
        else:
            click.echo("Rate limit exceeded", err=True)
            sys.exit(1)
```

---

## CI/CD Pipeline Examples

### GitHub Actions - Complete Integration

```yaml
name: CodeRabbit Review - Production Ready

on:
  pull_request:
    types: [opened, synchronize, reopened]
  push:
    branches: [main, develop]

env:
  # Enhancement 1: Secrets in environment (will be sanitized in logs)
  CODERABBIT_API_KEY: ${{ secrets.CODERABBIT_API_KEY }}
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

jobs:
  coderabbit-review:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for git diff

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install CodeRabbit MCP
        run: |
          pip install -e /srv/cc/coderabbit-mcp

      # Enhancement 2: Detect changed files
      - name: Detect Changed Files
        id: changes
        run: |
          CHANGED_FILES=$(git diff --name-only origin/${{ github.base_ref }}...HEAD)
          echo "files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          FILE_COUNT=$(echo "$CHANGED_FILES" | wc -l)
          echo "count=$FILE_COUNT" >> $GITHUB_OUTPUT

          echo "Changed files: $FILE_COUNT"

      # Enhancement 3: Review with rate limit handling
      - name: CodeRabbit Review
        id: review
        continue-on-error: true
        run: |
          python -m coderabbit_mcp.cli review \
            --repo ${{ github.repository }} \
            --pr ${{ github.event.pull_request.number }} \
            --incremental \
            --rate-limit-strategy graceful \
            --output review-results.json

      # Enhancement 1: Logs automatically sanitized
      - name: Display Review Results
        run: |
          if [ -f review-results.json ]; then
            cat review-results.json
          fi

      - name: Handle Review Status
        run: |
          STATUS=$(jq -r '.status' review-results.json)

          if [ "$STATUS" = "success" ]; then
            echo "✅ Full review completed"
            echo "Files reviewed: $(jq -r '.files_reviewed' review-results.json)"
          elif [ "$STATUS" = "partial" ]; then
            echo "⚠️ Partial review (rate limit hit)"
            echo "Scope: $(jq -r '.scope' review-results.json)"
            echo "Rationale: $(jq -r '.rationale' review-results.json)"
          elif [ "$STATUS" = "skipped" ]; then
            echo "⚠️ Review skipped (rate limit exhausted)"
            echo "Rationale: $(jq -r '.rationale' review-results.json)"
          fi

          # Always succeed - don't block pipeline
          exit 0

      - name: Upload Review Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coderabbit-review
          path: review-results.json

      - name: Performance Metrics
        run: |
          echo "Review Performance:"
          echo "- Changed files: ${{ steps.changes.outputs.count }}"
          echo "- Review mode: Incremental"
          echo "- Duration: ${{ steps.review.outputs.duration }}s"
```

### GitLab CI - Complete Integration

```yaml
# .gitlab-ci.yml

variables:
  # Enhancement 1: Secrets (sanitized in logs)
  CODERABBIT_API_KEY: $CODERABBIT_API_KEY
  GIT_DEPTH: 0  # Full history for diffs

stages:
  - review

coderabbit-review:
  stage: review
  image: python:3.11

  before_script:
    - pip install -e /srv/cc/coderabbit-mcp

  script:
    # Enhancement 2: Detect changed files
    - |
      CHANGED_FILES=$(git diff --name-only origin/$CI_MERGE_REQUEST_TARGET_BRANCH_NAME...HEAD)
      FILE_COUNT=$(echo "$CHANGED_FILES" | wc -l)
      echo "Changed files: $FILE_COUNT"

    # Enhancement 3: Review with rate limit handling
    - |
      python -m coderabbit_mcp.cli review \
        --repo $CI_PROJECT_PATH \
        --pr $CI_MERGE_REQUEST_IID \
        --incremental \
        --rate-limit-strategy graceful \
        --output review-results.json

    # Display results
    - cat review-results.json

    # Handle status
    - |
      STATUS=$(jq -r '.status' review-results.json)

      if [ "$STATUS" = "partial" ] || [ "$STATUS" = "skipped" ]; then
        echo "⚠️ Review completed with warnings"
        echo "Rationale: $(jq -r '.rationale' review-results.json)"
      else
        echo "✅ Full review completed"
      fi

  artifacts:
    paths:
      - review-results.json
    expire_in: 7 days

  allow_failure: true  # Don't block pipeline on rate limits

  only:
    - merge_requests
```

### Jenkins - Complete Integration

```groovy
// Jenkinsfile

pipeline {
    agent any

    environment {
        // Enhancement 1: Secrets (sanitized)
        CODERABBIT_API_KEY = credentials('coderabbit-api-key')
        GITHUB_TOKEN = credentials('github-token')
    }

    stages {
        stage('Setup') {
            steps {
                sh 'pip install -e /srv/cc/coderabbit-mcp'
            }
        }

        stage('Detect Changes') {
            steps {
                script {
                    // Enhancement 2: Incremental review
                    env.CHANGED_FILES = sh(
                        script: "git diff --name-only origin/${env.CHANGE_TARGET}...HEAD",
                        returnStdout: true
                    ).trim()

                    env.FILE_COUNT = sh(
                        script: "echo '${env.CHANGED_FILES}' | wc -l",
                        returnStdout: true
                    ).trim()

                    echo "Changed files: ${env.FILE_COUNT}"
                }
            }
        }

        stage('CodeRabbit Review') {
            steps {
                script {
                    // Enhancement 3: Rate limit handling
                    sh """
                        python -m coderabbit_mcp.cli review \
                          --repo ${env.GIT_URL} \
                          --pr ${env.CHANGE_ID} \
                          --incremental \
                          --rate-limit-strategy graceful \
                          --output review-results.json || true
                    """

                    // Parse results
                    def results = readJSON file: 'review-results.json'

                    if (results.status == 'partial' || results.status == 'skipped') {
                        echo "⚠️ Review completed with warnings"
                        echo "Rationale: ${results.rationale}"
                    } else {
                        echo "✅ Full review completed"
                    }
                }
            }
        }
    }

    post {
        always {
            archiveArtifacts artifacts: 'review-results.json', allowEmptyArchive: true
        }
    }
}
```

---

## Timeline

### Implementation Schedule

**Total Effort**: 7 hours

**Phase 1: Enhancement 1 - Secret Sanitization** (2 hours)
- Hour 1: Implement `SecretSanitizer` and `SanitizingLogger`
- Hour 2: Integrate into MCP server, write unit tests

**Phase 2: Enhancement 2 - Incremental Review** (3 hours)
- Hour 1: Implement `GitDiffDetector`
- Hour 2: Integrate incremental review into MCP tools
- Hour 3: Create GitHub Actions integration, write tests

**Phase 3: Enhancement 3 - Rate Limit Handling** (2 hours)
- Hour 1: Implement `RateLimitHandler` and fallback strategy
- Hour 2: Integrate into MCP tools, write tests

**Milestone Deliverables:**
- After 2 hours: Secret sanitization working, logs secure
- After 5 hours: Incremental review working, 60-80% performance improvement
- After 7 hours: Rate limit handling working, pipeline resilient

### Testing Schedule

**Unit Tests**: 1 hour (parallel with implementation)
**Integration Tests**: 1 hour (after all enhancements complete)
**CI/CD Pipeline Tests**: 1 hour (validate GitHub Actions, GitLab CI)

**Total Testing**: 3 hours

### Deployment Schedule

**Documentation**: 1 hour (this document complete)
**Code Review**: 1 hour (Carlos reviews implementation)
**Deployment**: 0.5 hours (merge to main, deploy to servers)

**Total Deployment**: 2.5 hours

---

## Dependencies

### Before Eric Can Implement

**Required:**
1. ✅ Parser complete (Carlos - DONE)
2. ✅ CLI wrapper complete (Carlos - DONE)
3. ✅ MCP server running (Carlos - DONE)
4. ✅ This specification document (Isaac - NOW)

**Optional:**
5. Test repository with PRs (for integration testing)
6. CodeRabbit API access (for rate limit testing)

### Eric Needs Access To

**Code Repositories:**
- `/srv/cc/coderabbit-mcp` (read/write access)
- Test repository (for PR testing)

**Infrastructure:**
- hx-cc-server.hx.dev.local (for MCP server deployment)
- GitHub Actions runner (for CI/CD testing)

**Credentials:**
- CodeRabbit API key (for testing)
- GitHub token (for PR access)

### Integration Points

**Coordinates With:**
- Carlos Martinez: Parser and wrapper integration
- Isaac Morgan: CI/CD pipeline validation (you)
- Julia Santos: Test automation

**Depends On:**
- Carlos's parser (complete)
- Carlos's wrapper (complete)
- MCP server infrastructure (running)

---

## Quality Assurance

### Code Quality Standards

**All code must:**
- Follow PEP 8 Python style guide
- Include type hints
- Have docstrings for all functions
- Pass `mypy` type checking
- Pass `pylint` with score > 9.0
- Have unit test coverage > 90%

### Testing Requirements

**Unit Tests:**
- Test all secret patterns
- Test git diff detection
- Test rate limit retry logic
- Test fallback strategies
- Mock external dependencies

**Integration Tests:**
- Test end-to-end review flow
- Test GitHub Actions integration
- Test rate limit scenarios
- Test incremental vs full review performance

### Documentation Requirements

**Code Documentation:**
- Docstrings for all modules, classes, functions
- Inline comments for complex logic
- Type hints for all parameters and returns

**User Documentation:**
- README with usage examples
- CI/CD integration guide
- Troubleshooting guide

---

## Success Metrics

### Performance Metrics

**Enhancement 2 - Incremental Review:**
- Target: 60-80% faster than full review
- Baseline: Full review = 3-5 minutes
- Target: Incremental review = 30-60 seconds

### Reliability Metrics

**Enhancement 3 - Rate Limit Handling:**
- Target: 0 pipeline failures due to rate limits
- Target: 95% of reviews complete successfully
- Target: < 5% fallback to critical-only mode

### Security Metrics

**Enhancement 1 - Secret Sanitization:**
- Target: 0 secrets exposed in logs
- Target: 100% of secret patterns detected
- Target: All unit tests pass

---

## Document Metadata

```yaml
document_type: Implementation Specification
author: Isaac Morgan
agent_role: CI/CD Integration Specialist
created_date: 2025-11-10
status: Ready for Implementation
assigned_to: Eric Johnson
estimated_effort: 7 hours
priority: CRITICAL (Blocking for production)
dependencies:
  - Parser (Carlos - Complete)
  - CLI Wrapper (Carlos - Complete)
  - MCP Server (Carlos - Running)
location: /srv/cc/Governance/x-poc4-coderabbit/0.1-Planning/0.1.8-CICD-ENHANCEMENTS.md
```

---

**END OF SPECIFICATION**

Eric, this document provides everything you need to implement the three critical CI/CD enhancements. Each enhancement includes:

- Detailed requirements
- Implementation approach with code examples
- Testing strategy
- Success criteria
- CI/CD pipeline integration examples

Please let me know if you need any clarification on the specifications.

**Estimated implementation time: 7 hours**

Good luck!

- Isaac Morgan, CI/CD Integration Specialist
