Available Commands
Run Review

Basic:
coderabbit-json

With options:
coderabbit-json --mode security
coderabbit-json --mode quality
coderabbit-json --path src/backend
coderabbit-json --save-log

Parse Results
The command outputs structured JSON:
{
  "status": "completed",
  "total_issues": 3,
  "critical_issues": 1,
  "high_issues": 1,
  "medium_issues": 1,
  "low_issues": 0,
  "issues": [
    {
      "id": "DEF-001",
      "priority": "P0",
      "type": "security",
      "file": "src/auth.py",
      "line": 42,
      "message": "Hardcoded API key detected",
      "description": "...",
      "suggested_fix": "Move to environment variable...",
      "reference": "Hana-X Standards: Section 4.2"
    }
  ],
  "summary": "Found 3 issues: ðŸ”´ 1 critical (P0) | ðŸŸ¡ 1 high (P1) | âš« 1 medium (P2)"
}
```

---

## Natural Language Usage in Claude Code

### Example 1: Quick Review

**You say**:
```
"Run CodeRabbit and tell me what issues exist"
```

**Claude does**:
1. Runs: `coderabbit-json`
2. Parses JSON output
3. Responds:
```
   CodeRabbit found 3 issues:
   
   ðŸ”´ P0 (Critical): Hardcoded API key in src/auth.py:42
      Fix: Move to environment variable
   
   ðŸŸ¡ P1 (High): Missing type hints in src/utils.py:15
      Fix: Add type annotations
   
   âš« P2 (Medium): Function complexity in src/process.py:89
      Fix: Extract sub-functions
```

---

### Example 2: Auto-Fix Workflow

**You say**:
```
"Run CodeRabbit and fix all P0 and P1 issues"
```

**Claude does**:
1. Runs: `coderabbit-json`
2. Identifies P0 and P1 issues
3. For each issue:
   - Reads file and line number
   - Applies suggested fix
   - Commits change
4. Re-runs: `coderabbit-json`
5. Verifies fixes worked
6. Responds:
```
   Fixed 2 critical issues:
   
   âœ… src/auth.py:42 - Moved API key to environment variable
      Updated code to use os.getenv('API_KEY')
   
   âœ… src/utils.py:15 - Added type hints
      Added annotations: def process_data(input: str, config: Config) -> Result
   
   Re-ran CodeRabbit: âœ… No P0/P1 issues remain
```

---

### Example 3: Security-Focused Review

**You say**:
```
"Run a security scan with CodeRabbit and fix any vulnerabilities"
```

**Claude does**:
1. Runs: `coderabbit-json --mode security`
2. Focuses on security issues only
3. Auto-fixes all security problems
4. Responds with summary

---

### Example 4: Pre-Deployment Check

**You say**:
```
"Before I deploy, run a complete CodeRabbit review and make sure nothing is blocking"
```

**Claude does**:
1. Runs: `coderabbit-json --save-log`
2. Shows all issues
3. Highlights any P0 issues that block deployment
4. Saves to DEFECT-LOG.md
5. Responds:
```
   Complete review finished:
   
   Total: 5 issues
   ðŸ”´ P0: 0 (âœ… None blocking deployment)
   ðŸŸ¡ P1: 2 (Should fix before merge)
   âš« P2: 3 (Can fix later)
   
   Saved detailed report to DEFECT-LOG.md
   
   âœ… Safe to deploy - no critical issues

Integration with Roger
For advanced workflows, you can also use Roger:
# Roger orchestrates CodeRabbit
roger review --auto-fix

# Roger tracks defects across sessions
roger status
roger report

Difference:

coderabbit-json: Direct, lightweight, for Claude Code
roger review: Full orchestration, background processing, history tracking

Use coderabbit-json when: Working interactively in Claude Code
Use roger when: CI/CD, scheduled reviews, comprehensive tracking

Understanding Output
Issue Priorities
PriorityMeaningAction RequiredðŸ”´ P0CriticalMust fix before deploymentðŸŸ¡ P1HighShould fix before mergeâš« P2MediumFix when convenientâšª P3LowNice to have
Issue Types
TypeExampleFix TimeSecurityHardcoded secrets, SQL injectionImmediateSOLID ViolationSingle Responsibility breach15-30 minCode QualityMissing type hints5-10 minDocumentationMissing docstrings5 minTestingLow coverageVariesPerformanceHigh complexity15-30 min